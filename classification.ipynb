{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VARSHAJOSHY/multi-lingual-stance-dataset/blob/main/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqrpBxlL-VR8"
      },
      "source": [
        "\n",
        "**Name:** VARSHA JOSHY\n",
        "\n",
        "**Student Number:** 2699662J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWZ4t4Ut91ur"
      },
      "source": [
        "# **TextAs Data Coursework**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyFYH3v7-ix0"
      },
      "source": [
        "## **Downloading and loading Data**\n",
        "\n",
        "**This code loads the prepared split of the Reddit data into training, validation and testing set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG_zJqYH9sTd",
        "outputId": "27395a45-cebe-4903-ae0b-8aaadc75c024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-14 16:27:38--  https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EapVNOIV84tPnQuuFBNgG9UBYIWipQ9JL4QTfSgRtIacBw?download=1\n",
            "Resolving gla-my.sharepoint.com (gla-my.sharepoint.com)... 13.107.136.9, 13.107.138.9\n",
            "Connecting to gla-my.sharepoint.com (gla-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/jake_lever_glasgow_ac_uk/Documents/Teaching/reddit_data_split.zip?ga=1 [following]\n",
            "--2022-07-14 16:27:39--  https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/Documents/Teaching/reddit_data_split.zip?ga=1\n",
            "Reusing existing connection to gla-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 468327 (457K) [application/x-zip-compressed]\n",
            "Saving to: ‘reddit_data_split.zip’\n",
            "\n",
            "reddit_data_split.z 100%[===================>] 457.35K   694KB/s    in 0.7s    \n",
            "\n",
            "2022-07-14 16:27:40 (694 KB/s) - ‘reddit_data_split.zip’ saved [468327/468327]\n",
            "\n",
            "Archive:  reddit_data_split.zip\n",
            "  inflating: reddit_test.json        \n",
            "  inflating: reddit_train.json       \n",
            "  inflating: reddit_val.json         \n"
          ]
        }
      ],
      "source": [
        "!wget -O reddit_data_split.zip https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EapVNOIV84tPnQuuFBNgG9UBYIWipQ9JL4QTfSgRtIacBw?download=1\n",
        "!unzip -o reddit_data_split.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCezGTgdRYkj",
        "outputId": "3a941aa2-0694-4b24-b751-03abc9de510b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of posts in training data: 1200\n",
            "Number of posts in validation data: 400\n",
            "Number of posts in test data: 400\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open('reddit_train.json') as f:\n",
        "    train_data = json.load(f)\n",
        "with open('reddit_val.json') as f:\n",
        "    validation_data = json.load(f)\n",
        "with open('reddit_test.json') as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "print(\"Number of posts in training data:\", len(train_data))\n",
        "print(\"Number of posts in validation data:\", len(validation_data))\n",
        "print(\"Number of posts in test data:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzmCpxLYbdOI"
      },
      "source": [
        "**This code block download libraries/functions from various modules that are required to execute the collab/notebook**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1Qw1AzsbZjV",
        "outputId": "f6543f3b-c0db-472c-848c-c30525dac8f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import collections\n",
        "\n",
        "# Load the medium english model.\n",
        "# We will use this model to get embedding features for tokens later.\n",
        "#!python -m spacy download en_core_web_md\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
        "nlp.remove_pipe('tagger')\n",
        "nlp.remove_pipe('parser')\n",
        "\n",
        "# Download a stopword list\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from pprint import pprint\n",
        "from time import time\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "#Python, pandas\n",
        "#Function on CSS created for this\n",
        "from IPython.display import display_html\n",
        "\n",
        "#custom tokenization\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#gensim word2vec libraries\n",
        "import gensim.downloader as gensim_api\n",
        "import gensim\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from gensim.sklearn_api import W2VTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7txBmrCG_tKr"
      },
      "source": [
        "## **Q1: Comparing Classifiers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK9u5izk_wSh"
      },
      "source": [
        "#### **Q1a: Exploring Dataset**\n",
        "Calculate the counts for the various labels and comment on the distribution of labels in the training/validation/test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLL0ZNidd1dX"
      },
      "source": [
        "\n",
        "\n",
        "*   **Training Dataset**\n",
        "is used to train the model or fit the parameters to the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "kQRKOn5B2Drm",
        "outputId": "925d8e01-3026-4776-feaf-e2fae278cae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 1200 Reddit posts in training dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           subreddit                                              title  \\\n",
              "0                PS4  Can I get banned for having a game that I didn...   \n",
              "1           pcgaming      How to get a Kinect sensor to work with a PC?   \n",
              "2     NintendoSwitch               Switch Only Charges with GoPro Cable   \n",
              "3            antiMLM                   L’Occitane going down MLM route?   \n",
              "4        HydroHomies                              Guys i need your help   \n",
              "...              ...                                                ...   \n",
              "1195            xbox  I’m debating if I should get a PC or Xbox Seri...   \n",
              "1196          Coffee  Where can I buy several exotic or unique coffees?   \n",
              "1197             tea  What are some of y'all's favorite non-caffeina...   \n",
              "1198          Coffee            [Q] What pour over method should I try?   \n",
              "1199        pcgaming           Thoughts on the Asus G Series G5S3W-XN1?   \n",
              "\n",
              "      score      id            author  \\\n",
              "0         0  queqfu           XC-XERZ   \n",
              "1         0  1eujoa       ZachTheKing   \n",
              "2         5  m00bx7   BluePenguin2002   \n",
              "3        15  q13pvx   100fluffyclouds   \n",
              "4         2  rxiv2g    Epicskeleton53   \n",
              "...     ...     ...               ...   \n",
              "1195      2  m6a172          Matt3339   \n",
              "1196     10  3yvspn    victorlinguist   \n",
              "1197      5  bdlfo5    Bobthebanana73   \n",
              "1198      7  htwdo3  NorwegianWarlord   \n",
              "1199      6   iy1zg       aznegglover   \n",
              "\n",
              "                                                   body  \n",
              "0     Long story short, I saw ESO in my library, dow...  \n",
              "1     I have seen a video online where someone took ...  \n",
              "2     Hi, hope this is the right place/way to post t...  \n",
              "3     After buying a majority share in Limelight/Alc...  \n",
              "4     Is it ok for me to drink coffee in the morning...  \n",
              "...                                                 ...  \n",
              "1195  I do have some question as well.\\n1. Can the S...  \n",
              "1196  I am looking for an online place that will off...  \n",
              "1197  Due to medical reasons, I am currently not all...  \n",
              "1198  Hey all!\\nThe recent years I've learned to lov...  \n",
              "1199  http://www.newegg.com/Product/Product.aspx?Ite...  \n",
              "\n",
              "[1200 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b26d02f5-43a1-40be-9677-eca0475f1a15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PS4</td>\n",
              "      <td>Can I get banned for having a game that I didn...</td>\n",
              "      <td>0</td>\n",
              "      <td>queqfu</td>\n",
              "      <td>XC-XERZ</td>\n",
              "      <td>Long story short, I saw ESO in my library, dow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pcgaming</td>\n",
              "      <td>How to get a Kinect sensor to work with a PC?</td>\n",
              "      <td>0</td>\n",
              "      <td>1eujoa</td>\n",
              "      <td>ZachTheKing</td>\n",
              "      <td>I have seen a video online where someone took ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NintendoSwitch</td>\n",
              "      <td>Switch Only Charges with GoPro Cable</td>\n",
              "      <td>5</td>\n",
              "      <td>m00bx7</td>\n",
              "      <td>BluePenguin2002</td>\n",
              "      <td>Hi, hope this is the right place/way to post t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>antiMLM</td>\n",
              "      <td>L’Occitane going down MLM route?</td>\n",
              "      <td>15</td>\n",
              "      <td>q13pvx</td>\n",
              "      <td>100fluffyclouds</td>\n",
              "      <td>After buying a majority share in Limelight/Alc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HydroHomies</td>\n",
              "      <td>Guys i need your help</td>\n",
              "      <td>2</td>\n",
              "      <td>rxiv2g</td>\n",
              "      <td>Epicskeleton53</td>\n",
              "      <td>Is it ok for me to drink coffee in the morning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>xbox</td>\n",
              "      <td>I’m debating if I should get a PC or Xbox Seri...</td>\n",
              "      <td>2</td>\n",
              "      <td>m6a172</td>\n",
              "      <td>Matt3339</td>\n",
              "      <td>I do have some question as well.\\n1. Can the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>Where can I buy several exotic or unique coffees?</td>\n",
              "      <td>10</td>\n",
              "      <td>3yvspn</td>\n",
              "      <td>victorlinguist</td>\n",
              "      <td>I am looking for an online place that will off...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>tea</td>\n",
              "      <td>What are some of y'all's favorite non-caffeina...</td>\n",
              "      <td>5</td>\n",
              "      <td>bdlfo5</td>\n",
              "      <td>Bobthebanana73</td>\n",
              "      <td>Due to medical reasons, I am currently not all...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>[Q] What pour over method should I try?</td>\n",
              "      <td>7</td>\n",
              "      <td>htwdo3</td>\n",
              "      <td>NorwegianWarlord</td>\n",
              "      <td>Hey all!\\nThe recent years I've learned to lov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>pcgaming</td>\n",
              "      <td>Thoughts on the Asus G Series G5S3W-XN1?</td>\n",
              "      <td>6</td>\n",
              "      <td>iy1zg</td>\n",
              "      <td>aznegglover</td>\n",
              "      <td>http://www.newegg.com/Product/Product.aspx?Ite...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b26d02f5-43a1-40be-9677-eca0475f1a15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b26d02f5-43a1-40be-9677-eca0475f1a15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b26d02f5-43a1-40be-9677-eca0475f1a15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "collabels = ['subreddit', 'title', 'score', 'id', 'author','body']\n",
        "train_data_list = list()\n",
        "for pos, item in enumerate(train_data):\n",
        "    train_data_list.append( (train_data[pos]['subreddit'], train_data[pos]['title'], train_data[pos]['score'], train_data[pos]['id'], train_data[pos]['author'], train_data[pos]['body']))\n",
        "print(\"We have %d Reddit posts in training dataset\"  % len(train_data_list))\n",
        "train_data_df = pd.DataFrame(train_data_list, columns=collabels)\n",
        "train_data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEln2KBJkU2a"
      },
      "source": [
        "\n",
        "*   **Validation Dataset**\n",
        "is used to provide an unbiased evaluation of a model fitted on the training dataset as well as tuning hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "6boLcMbfkEXC",
        "outputId": "8e3dad50-a993-419e-a67e-df2ffce755e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 400 Reddit posts in validation dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       subreddit                                              title  score  \\\n",
              "0         Coffee                            Reusable Nespresso Pods      3   \n",
              "1    HydroHomies  Hydro News (sad) A city in US Michigan, Benton...      8   \n",
              "2           Soda  Can’t find Sprite Zero Sugar Winter Spiced Cra...      2   \n",
              "3            tea  I have a lot of teas, loose and in bags, that ...     11   \n",
              "4         Coffee    Should I rinse bamboo filters before pour over?      0   \n",
              "..           ...                                                ...    ...   \n",
              "395         Soda  Where and How can i preserve collectable sodas...      0   \n",
              "396         Soda                   What American Soda should I get?      2   \n",
              "397         xbox                     refund bought with a gift card      3   \n",
              "398          PS4                                GTA V install crash      0   \n",
              "399          tea  I'm fairly new to the world of tea. Getting of...      4   \n",
              "\n",
              "         id               author  \\\n",
              "0    j4d0i9           SaltyRob78   \n",
              "1    q6lb22         Kirinsdragon   \n",
              "2    rs0qmb      AnonymousPete23   \n",
              "3    egwnfh  T_as_in_Pterodactyl   \n",
              "4    pkxx4y             jack_hof   \n",
              "..      ...                  ...   \n",
              "395  lvjhhw            Pokeboy99   \n",
              "396  kuo4ky   Old_Advantage_2341   \n",
              "397  rtvh45           SwingStuff   \n",
              "398  legirx           firewolf37   \n",
              "399  mz2kcv     frijolita_bonita   \n",
              "\n",
              "                                                  body  \n",
              "0    Hey there\\nI want to go the reusable pod route...  \n",
              "1    I am not from the US and such news never reach...  \n",
              "2    Sprite released this limited edition soda for ...  \n",
              "3    Long story short, I just have too many teas in...  \n",
              "4    Having a hard time finding an answer to this w...  \n",
              "..                                                 ...  \n",
              "395  I've had some sodas that i wanted to keep leak...  \n",
              "396  So I recently started selling an American Trea...  \n",
              "397  just wondering if i bought something with a gi...  \n",
              "398  so i decided to reinstall gta v after the cayo...  \n",
              "399  I've been drinking hibiscus tea and another lo...  \n",
              "\n",
              "[400 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bcc520d-4049-4160-9ffe-c3adba0bf605\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>Reusable Nespresso Pods</td>\n",
              "      <td>3</td>\n",
              "      <td>j4d0i9</td>\n",
              "      <td>SaltyRob78</td>\n",
              "      <td>Hey there\\nI want to go the reusable pod route...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HydroHomies</td>\n",
              "      <td>Hydro News (sad) A city in US Michigan, Benton...</td>\n",
              "      <td>8</td>\n",
              "      <td>q6lb22</td>\n",
              "      <td>Kirinsdragon</td>\n",
              "      <td>I am not from the US and such news never reach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Soda</td>\n",
              "      <td>Can’t find Sprite Zero Sugar Winter Spiced Cra...</td>\n",
              "      <td>2</td>\n",
              "      <td>rs0qmb</td>\n",
              "      <td>AnonymousPete23</td>\n",
              "      <td>Sprite released this limited edition soda for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tea</td>\n",
              "      <td>I have a lot of teas, loose and in bags, that ...</td>\n",
              "      <td>11</td>\n",
              "      <td>egwnfh</td>\n",
              "      <td>T_as_in_Pterodactyl</td>\n",
              "      <td>Long story short, I just have too many teas in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>Should I rinse bamboo filters before pour over?</td>\n",
              "      <td>0</td>\n",
              "      <td>pkxx4y</td>\n",
              "      <td>jack_hof</td>\n",
              "      <td>Having a hard time finding an answer to this w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>Soda</td>\n",
              "      <td>Where and How can i preserve collectable sodas...</td>\n",
              "      <td>0</td>\n",
              "      <td>lvjhhw</td>\n",
              "      <td>Pokeboy99</td>\n",
              "      <td>I've had some sodas that i wanted to keep leak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>Soda</td>\n",
              "      <td>What American Soda should I get?</td>\n",
              "      <td>2</td>\n",
              "      <td>kuo4ky</td>\n",
              "      <td>Old_Advantage_2341</td>\n",
              "      <td>So I recently started selling an American Trea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>xbox</td>\n",
              "      <td>refund bought with a gift card</td>\n",
              "      <td>3</td>\n",
              "      <td>rtvh45</td>\n",
              "      <td>SwingStuff</td>\n",
              "      <td>just wondering if i bought something with a gi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>PS4</td>\n",
              "      <td>GTA V install crash</td>\n",
              "      <td>0</td>\n",
              "      <td>legirx</td>\n",
              "      <td>firewolf37</td>\n",
              "      <td>so i decided to reinstall gta v after the cayo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>tea</td>\n",
              "      <td>I'm fairly new to the world of tea. Getting of...</td>\n",
              "      <td>4</td>\n",
              "      <td>mz2kcv</td>\n",
              "      <td>frijolita_bonita</td>\n",
              "      <td>I've been drinking hibiscus tea and another lo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bcc520d-4049-4160-9ffe-c3adba0bf605')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5bcc520d-4049-4160-9ffe-c3adba0bf605 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5bcc520d-4049-4160-9ffe-c3adba0bf605');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "val_data_list = list()\n",
        "for pos, item in enumerate(validation_data):\n",
        "    val_data_list.append( (validation_data[pos]['subreddit'], validation_data[pos]['title'], validation_data[pos]['score'], validation_data[pos]['id'], validation_data[pos]['author'], validation_data[pos]['body']))\n",
        "print(\"We have %d Reddit posts in validation dataset\"  % len(val_data_list))\n",
        "val_data_df = pd.DataFrame(val_data_list, columns=collabels)\n",
        "val_data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l82wHqE-kRdL"
      },
      "source": [
        "*   **Test Dataset**\n",
        "is used to provide an unbiased evaluation of a final model fitted on the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "JrXKryfnkHwV",
        "outputId": "ccece8ea-dbb8-43a5-d821-37226d38af98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 400 Reddit posts in test dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          subreddit                                              title  score  \\\n",
              "0            Coffee         Best Indie Coffee Brands that have K-Cups?      0   \n",
              "1    NintendoSwitch  How do you decide when to keep playing or when...    125   \n",
              "2              xbox  So I’m relatively new on Xbox, and have a ques...      1   \n",
              "3               tea                    Best gyokuro vendors in the US?      5   \n",
              "4           antiMLM  My Mary Kay hun neighbor has a \"no soliciting\"...   1038   \n",
              "..              ...                                                ...    ...   \n",
              "395        pcgaming  I'm blown away by how much better Linux suppor...    152   \n",
              "396  NintendoSwitch        TIL I can use USB-C Headphones on my Switch    213   \n",
              "397  NintendoSwitch  Shin Megami Tensei V is the Dark Souls of Poke...      0   \n",
              "398        pcgaming  Gaming 20 years in the future, what are your o...     35   \n",
              "399            Soda  Where can I buy Fanta Shokata (Elderberry - Le...      1   \n",
              "\n",
              "         id               author  \\\n",
              "0    3s7usq  GrandRapidsCreative   \n",
              "1    r8luun             windlep7   \n",
              "2    qwzis0        GoblinGuide93   \n",
              "3    m1m3as        SocioDexter70   \n",
              "4    pg5gs0        OkWallaby0009   \n",
              "..      ...                  ...   \n",
              "395  fv1cgw          UnDispelled   \n",
              "396  anqw0e               LufiXx   \n",
              "397  r1ev6l           ramen_junk   \n",
              "398  pj00n4    Pretend-Tangelo56   \n",
              "399  rui7se          piotrowskid   \n",
              "\n",
              "                                                  body  \n",
              "0    I know most aren't the biggest fan of K-Cups a...  \n",
              "1    I know the obvious answer is to give up if you...  \n",
              "2    I was playing infinite with friends in the par...  \n",
              "3    Ive only ever tried Ippodo since they have a U...  \n",
              "4    I guess she doesn't like to be bothered by peo...  \n",
              "..                                                 ...  \n",
              "395  This is just a post I wanted to make praising ...  \n",
              "396  While on the train this morning i put in my Hu...  \n",
              "397  This is the first SMT game I ever played and I...  \n",
              "398  I urge you to be creative with your opinions.\\...  \n",
              "399  The soda is so good. I first tried it when I w...  \n",
              "\n",
              "[400 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f41fd826-b416-41e3-b07a-c90164fa12fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>Best Indie Coffee Brands that have K-Cups?</td>\n",
              "      <td>0</td>\n",
              "      <td>3s7usq</td>\n",
              "      <td>GrandRapidsCreative</td>\n",
              "      <td>I know most aren't the biggest fan of K-Cups a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NintendoSwitch</td>\n",
              "      <td>How do you decide when to keep playing or when...</td>\n",
              "      <td>125</td>\n",
              "      <td>r8luun</td>\n",
              "      <td>windlep7</td>\n",
              "      <td>I know the obvious answer is to give up if you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xbox</td>\n",
              "      <td>So I’m relatively new on Xbox, and have a ques...</td>\n",
              "      <td>1</td>\n",
              "      <td>qwzis0</td>\n",
              "      <td>GoblinGuide93</td>\n",
              "      <td>I was playing infinite with friends in the par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tea</td>\n",
              "      <td>Best gyokuro vendors in the US?</td>\n",
              "      <td>5</td>\n",
              "      <td>m1m3as</td>\n",
              "      <td>SocioDexter70</td>\n",
              "      <td>Ive only ever tried Ippodo since they have a U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>antiMLM</td>\n",
              "      <td>My Mary Kay hun neighbor has a \"no soliciting\"...</td>\n",
              "      <td>1038</td>\n",
              "      <td>pg5gs0</td>\n",
              "      <td>OkWallaby0009</td>\n",
              "      <td>I guess she doesn't like to be bothered by peo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>pcgaming</td>\n",
              "      <td>I'm blown away by how much better Linux suppor...</td>\n",
              "      <td>152</td>\n",
              "      <td>fv1cgw</td>\n",
              "      <td>UnDispelled</td>\n",
              "      <td>This is just a post I wanted to make praising ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>NintendoSwitch</td>\n",
              "      <td>TIL I can use USB-C Headphones on my Switch</td>\n",
              "      <td>213</td>\n",
              "      <td>anqw0e</td>\n",
              "      <td>LufiXx</td>\n",
              "      <td>While on the train this morning i put in my Hu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>NintendoSwitch</td>\n",
              "      <td>Shin Megami Tensei V is the Dark Souls of Poke...</td>\n",
              "      <td>0</td>\n",
              "      <td>r1ev6l</td>\n",
              "      <td>ramen_junk</td>\n",
              "      <td>This is the first SMT game I ever played and I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>pcgaming</td>\n",
              "      <td>Gaming 20 years in the future, what are your o...</td>\n",
              "      <td>35</td>\n",
              "      <td>pj00n4</td>\n",
              "      <td>Pretend-Tangelo56</td>\n",
              "      <td>I urge you to be creative with your opinions.\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>Soda</td>\n",
              "      <td>Where can I buy Fanta Shokata (Elderberry - Le...</td>\n",
              "      <td>1</td>\n",
              "      <td>rui7se</td>\n",
              "      <td>piotrowskid</td>\n",
              "      <td>The soda is so good. I first tried it when I w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f41fd826-b416-41e3-b07a-c90164fa12fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f41fd826-b416-41e3-b07a-c90164fa12fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f41fd826-b416-41e3-b07a-c90164fa12fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "test_data_list = list()\n",
        "for pos, item in enumerate(test_data):\n",
        "    test_data_list.append( (test_data[pos]['subreddit'], test_data[pos]['title'], test_data[pos]['score'], test_data[pos]['id'], test_data[pos]['author'], test_data[pos]['body']))\n",
        "print(\"We have %d Reddit posts in test dataset\"  % len(test_data_list))\n",
        "test_data_df = pd.DataFrame(test_data_list, columns=collabels)\n",
        "test_data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIQeFE1tt_6U"
      },
      "source": [
        "\n",
        "\n",
        "*  **Label distribution in Training/Validation/Test dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV8Js_EDuhBe"
      },
      "source": [
        "**display_side_by_side** function used for displaying two dataframes side my side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNMTEbX0btI9"
      },
      "outputs": [],
      "source": [
        "def display_side_by_side(*args):\n",
        "    html_str=''\n",
        "    for df in args:\n",
        "        html_str+=df.to_html()\n",
        "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "Lm1jqVJ9yl5I",
        "outputId": "91b7c975-8110-47b1-f968-6ff1b21c0728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data contains 9 unique labels/subreddit\n",
            "Validation data contains 9 unique labels/subreddit\n",
            "Test data contains 9 unique labels/subreddit\n",
            "\n",
            "     Distribution of labels in Training set      Distribution of labels in Validation set          Distribution of labels in Test set\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>count</th>\n",
              "      <th>prior_probabilities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PS4</td>\n",
              "      <td>142</td>\n",
              "      <td>0.118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pcgaming</td>\n",
              "      <td>135</td>\n",
              "      <td>0.112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NintendoSwitch</td>\n",
              "      <td>145</td>\n",
              "      <td>0.121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>antiMLM</td>\n",
              "      <td>128</td>\n",
              "      <td>0.107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HydroHomies</td>\n",
              "      <td>134</td>\n",
              "      <td>0.112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>136</td>\n",
              "      <td>0.113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>xbox</td>\n",
              "      <td>132</td>\n",
              "      <td>0.110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Soda</td>\n",
              "      <td>102</td>\n",
              "      <td>0.085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tea</td>\n",
              "      <td>146</td>\n",
              "      <td>0.122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>count</th>\n",
              "      <th>prior_probabilities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>42</td>\n",
              "      <td>0.105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HydroHomies</td>\n",
              "      <td>38</td>\n",
              "      <td>0.095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Soda</td>\n",
              "      <td>43</td>\n",
              "      <td>0.108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tea</td>\n",
              "      <td>48</td>\n",
              "      <td>0.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PS4</td>\n",
              "      <td>43</td>\n",
              "      <td>0.108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pcgaming</td>\n",
              "      <td>43</td>\n",
              "      <td>0.108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>xbox</td>\n",
              "      <td>37</td>\n",
              "      <td>0.092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NintendoSwitch</td>\n",
              "      <td>52</td>\n",
              "      <td>0.130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>antiMLM</td>\n",
              "      <td>54</td>\n",
              "      <td>0.135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>count</th>\n",
              "      <th>prior_probabilities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>56</td>\n",
              "      <td>0.140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NintendoSwitch</td>\n",
              "      <td>52</td>\n",
              "      <td>0.130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xbox</td>\n",
              "      <td>44</td>\n",
              "      <td>0.110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tea</td>\n",
              "      <td>42</td>\n",
              "      <td>0.105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>antiMLM</td>\n",
              "      <td>44</td>\n",
              "      <td>0.110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pcgaming</td>\n",
              "      <td>47</td>\n",
              "      <td>0.118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PS4</td>\n",
              "      <td>48</td>\n",
              "      <td>0.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HydroHomies</td>\n",
              "      <td>38</td>\n",
              "      <td>0.095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Soda</td>\n",
              "      <td>29</td>\n",
              "      <td>0.072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\">"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "figure, axes = plt.subplots(1, 3,figsize=(20,5))\n",
        "\n",
        "#training data\n",
        "uniquelabels_tr = train_data_df['subreddit'].unique()\n",
        "print(\"Training data contains %d unique labels/subreddit\" % len(uniquelabels_tr))\n",
        "\n",
        "tr_label_counts = collections.Counter(train_data_df['subreddit'])\n",
        "tr_list=[]\n",
        "for label in tr_label_counts:\n",
        "  tr_list.append([label,tr_label_counts[label],np.round(tr_label_counts[label] / len(train_data_df),3)])\n",
        "tr_label = pd.DataFrame(tr_list,columns=['subreddit','count','prior_probabilities'])\n",
        "tr_label.plot.bar(x='subreddit', y='count', ax=axes[0])\n",
        "axes[0].title.set_text(\"Distribution of labels in the Training set \")\n",
        "\n",
        "#validation data\n",
        "uniquelabels_val = val_data_df['subreddit'].unique()\n",
        "print(\"Validation data contains %d unique labels/subreddit\" % len(uniquelabels_val))\n",
        "\n",
        "val_label_counts = collections.Counter(val_data_df['subreddit'])\n",
        "val_list=[]\n",
        "for label in val_label_counts:\n",
        "  val_list.append([label,val_label_counts[label],np.round(val_label_counts[label] / len(val_data_df),3)])\n",
        "val_label = pd.DataFrame(val_list,columns=['subreddit','count','prior_probabilities'])\n",
        "val_label.plot.bar(x='subreddit', y='count', ax=axes[1])\n",
        "axes[1].title.set_text(\"Distribution of labels in the Validation set \")\n",
        "\n",
        "#test data\n",
        "uniquelabels_test = test_data_df['subreddit'].unique()\n",
        "print(\"Test data contains %d unique labels/subreddit\" % len(uniquelabels_test))\n",
        "\n",
        "test_label_counts = collections.Counter(test_data_df['subreddit'])\n",
        "test_list=[]\n",
        "for label in test_label_counts:\n",
        "  test_list.append([label,test_label_counts[label],np.round(test_label_counts[label] / len(test_data_df),3)])\n",
        "test_label = pd.DataFrame(test_list,columns=['subreddit','count','prior_probabilities'])\n",
        "test_label.style.set_caption(\"Training Set\")\n",
        "test_label.plot.bar(x='subreddit', y='count',ax=axes[2])\n",
        "axes[2].title.set_text(\"Distribution of labels in the Test set \")\n",
        "\n",
        "print()\n",
        "print(\"     Distribution of labels in Training set      Distribution of labels in Validation set          Distribution of labels in Test set\")\n",
        "display_side_by_side(tr_label,val_label,test_label)\n",
        "\n",
        "print()\n",
        "for ax in axes.flat:\n",
        "    ax.set(xlabel='subreddits', ylabel='Count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbAnmOn9Av2e"
      },
      "source": [
        "\n",
        "\n",
        "*   Analysing some statistics of datasets to check whether albels are evenly distributed among train, validation and test set. All of these labels appear in the three  datasets, however they are not uniformly distributed, and I suspcet that data is biased.\n",
        "*   For example, 8% training set data has label ‘soda’, while validation set has 11% soda label, and test set has a 7% soda label. Similarly, training set has 11% antiMLM as a label, while validation set has 14% antiMLM as a label, and test set has 11% antiMLM as a label.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "457VZaGZnfNV",
        "outputId": "d72e14a5-61ec-4ea6-ed5c-51b0cc21b586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set contains 8% soda as label\n",
            "Validation set contains 11% soda as label\n",
            "Test set contains 7% soda as label\n",
            "\n",
            "Training set contains 11% antiMLM as label\n",
            "Validation set contains 14% antiMLM as label\n",
            "Test set contains 11% antiMLM as label\n"
          ]
        }
      ],
      "source": [
        "number_soda_train = sum(train_data_df['subreddit'] == 'Soda')\n",
        "number_soda_val = sum(val_data_df['subreddit'] == 'Soda')\n",
        "number_soda_test = sum(test_data_df['subreddit'] == 'Soda')\n",
        "\n",
        "print('Training set contains %0.0f%% soda as label' % (100*number_soda_train/len(train_data_df)))\n",
        "print('Validation set contains %0.0f%% soda as label' % (100*number_soda_val/len(val_data_df)))\n",
        "print('Test set contains %0.0f%% soda as label' % (100*number_soda_test/len(test_data_df)))\n",
        "\n",
        "print()\n",
        "\n",
        "number_antiMLM_train = sum(train_data_df['subreddit'] == 'antiMLM')\n",
        "number_antiMLM_val = sum(val_data_df['subreddit'] == 'antiMLM')\n",
        "number_antiMLM_test = sum(test_data_df['subreddit'] == 'antiMLM')\n",
        "\n",
        "print('Training set contains %0.0f%% antiMLM as label' % (100*number_antiMLM_train/len(train_data_df)))\n",
        "print('Validation set contains %0.0f%% antiMLM as label' % (100*number_antiMLM_val/len(val_data_df)))\n",
        "print('Test set contains %0.0f%% antiMLM as label' % (100*number_antiMLM_test/len(test_data_df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11oTA7EIfNne"
      },
      "source": [
        "### **Q1b:Implementing Classifiers**\n",
        "Implement five classifiers, train them on the training set and evaluate on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNxOyNFdYLmd"
      },
      "source": [
        "**text_pipeline_spacy() function tokenize and normalize the text (column name - 'body') from reddit posts.**\n",
        ":Function split the text into group of words(also called tokens), eliminate stopwords, punctuations and space, and after lemmatization it return lower case tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sce05x5db3lc"
      },
      "outputs": [],
      "source": [
        "def text_pipeline_spacy(text):\n",
        "    tokens = []\n",
        "    doc = nlp(text)\n",
        "    for t in doc:\n",
        "        if not t.is_stop and not t.is_punct and not t.is_space:\n",
        "            tokens.append(t.lemma_.lower())\n",
        "    return tokens\n",
        "#text_pipeline_spacy(\"hHi How are you? What you doing?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"Iplacedanorder(order#ZA10880)on05-11-2020forrearaxlebreakdiscsforaBMW8Coupepartno.B342r.DH-Dhavelosttheorder.Pleasere-deliverASAP.\"\n",
        "doc = nlp(text)\n",
        "for t in doc:\n",
        "  print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sd3v-FDalXL",
        "outputId": "e568ed51-fbbd-41c6-dfd6-81feddd33172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iplacedanorder(order#ZA10880)on05\n",
            "-\n",
            "11\n",
            "-\n",
            "2020forrearaxlebreakdiscsforaBMW8Coupepartno\n",
            ".\n",
            "B342r\n",
            ".\n",
            "DH\n",
            "-\n",
            "Dhavelosttheorder\n",
            ".\n",
            "Pleasere\n",
            "-\n",
            "deliverASAP\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "pattern1 = r'(\\\\w+|\\\\?|!)'\n",
        "pattern2 = r\"(\\w+|#\\d|\\?|!)\"\n",
        "pattern3 = r'(#\\\\d\\\\w+\\\\?!)'\n",
        "pattern4 = r'\\\\s+'\n",
        "pprint(regexp_tokenize(text, pattern2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SKCfxbwiyCR",
        "outputId": "09c34a63-e709-42e9-b050-bb54d7e71522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Iplacedanorder',\n",
            " 'order',\n",
            " 'ZA10880',\n",
            " 'on05',\n",
            " '11',\n",
            " '2020forrearaxlebreakdiscsforaBMW8Coupepartno',\n",
            " 'B342r',\n",
            " 'DH',\n",
            " 'Dhavelosttheorder',\n",
            " 'Pleasere',\n",
            " 'deliverASAP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"Iplacedanorder(order#ZA10880)on05-11-2020forrearaxlebreakdiscsforaBMW8Coupepartno.B342r.DH-Dhavelosttheorder.Pleasere-deliverASAP.\"\n",
        "doc = nlp(text)\n",
        "for t in doc:\n",
        "  print(t)"
      ],
      "metadata": {
        "id": "FvPpgiKvh2Go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "896536df-2b55-4628-871e-95c3b3e67945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iplacedanorder(order#ZA10880)on05\n",
            "-\n",
            "11\n",
            "-\n",
            "2020forrearaxlebreakdiscsforaBMW8Coupepartno\n",
            ".\n",
            "B342r\n",
            ".\n",
            "DH\n",
            "-\n",
            "Dhavelosttheorder\n",
            ".\n",
            "Pleasere\n",
            "-\n",
            "deliverASAP\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"I placed an order (order# ZA10880) on 05-11-2020 for rear axle break discs for a BMW8Coupe - part no. B342r. DH-D have lost the order. Please re-deliver ASAP.\"\n",
        "doc = nlp(text)\n",
        "for t in doc:\n",
        "  print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8QRNBL1aa-j",
        "outputId": "2db50c41-82ba-4349-c067-fb6442592d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "placed\n",
            "an\n",
            "order\n",
            "(\n",
            "order\n",
            "#\n",
            "ZA10880\n",
            ")\n",
            "on\n",
            "05\n",
            "-\n",
            "11\n",
            "-\n",
            "2020\n",
            "for\n",
            "rear\n",
            "axle\n",
            "break\n",
            "discs\n",
            "for\n",
            "a\n",
            "BMW8Coupe\n",
            "-\n",
            "part\n",
            "no\n",
            ".\n",
            "B342r\n",
            ".\n",
            "DH\n",
            "-\n",
            "D\n",
            "have\n",
            "lost\n",
            "the\n",
            "order\n",
            ".\n",
            "Please\n",
            "re\n",
            "-\n",
            "deliver\n",
            "ASAP\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ItemSelector() function is a custome made transformer used for column selection** Result of this transformer is a dataframe"
      ],
      "metadata": {
        "id": "yjUe7_RoUtMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"[He didn’t like the U.S. movie “Snakes on a train, revenge of Viper-man!”, now playing in the U.K.]\"\n",
        "doc = nlp(text)\n",
        "for t in doc:\n",
        "  print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1e0adB_hBR-",
        "outputId": "57b134ae-b2f1-4b64-9b91-cef437d2b56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "He\n",
            "did\n",
            "n’t\n",
            "like\n",
            "the\n",
            "U.S.\n",
            "movie\n",
            "“\n",
            "Snakes\n",
            "on\n",
            "a\n",
            "train\n",
            ",\n",
            "revenge\n",
            "of\n",
            "Viper\n",
            "-\n",
            "man\n",
            "!\n",
            "”\n",
            ",\n",
            "now\n",
            "playing\n",
            "in\n",
            "the\n",
            "U.K.\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert pytorch-nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2ylV2nCrqIi",
        "outputId": "cd26d190-7ca9-43e6-c035-0f17667014f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.12.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.24.29)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.29 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.27.29)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.29->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.29->boto3->pytorch_pretrained_bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.29->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "qDCiqq3cWhF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qMqrPkqWik9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Data processing\n",
        "data = ... # Loads a vector of raw text documents\n",
        "train_index = int(len(train_data_df) * 0.1)\n",
        "print(train_index)\n",
        "train_data = data[:train_index,:]\n",
        "validation_data = data[int(train_index*0.2):,:]\n",
        "test_data = data[train_index:,:]\n",
        "# Assume corresponding labels for each data subset\n",
        "train_labels, test_labels, validation_labels = ...\n",
        "# Vectorization\n",
        "one_hot_vectorizer = CountVectorizer(tokenizer=tokenize_normalize,\n",
        "binary=True, max_features=20)\n",
        "one_hot_vectorizer.fit(train_data)\n",
        "train_features = one_hot_vectorizer.transform(train_features)\n",
        "validation_features = one_hot_vectorizer.fit_transform(validation_data)\n",
        "test_features = one_hot_vectorizer.transform(test_data)\n",
        "# Classification\n",
        "lr = LogisticRegression(solver='saga', max_iter=500)\n",
        "lr_model = lr.fit(train_features, train_labels)\n",
        "evaluation_summary(\"LR Train summary\",\n",
        "lr_model.predict(train_features), validation_labels)\n",
        "lr_model = lr.fit(validation_features, validation_features)\n",
        "evaluation_summary(\"LR Validation summary\",\n",
        "lr_model.predict(validation_features), validation_labels)\n",
        "lr_model = lr.fit(test_features, test_labels)\n",
        "evaluation_summary(\"LR Test summary\",\n",
        "lr_model.predict(validation_features), test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "NzyTUf2KWUbp",
        "outputId": "a9a1383c-7b54-4aad-ed0a-a38e3bbc503e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f7ff347f6960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertModel\n",
        "from torch import nn\n",
        "from torchnlp.datasets import imdb_dataset\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ],
      "metadata": {
        "id": "G9rBRIyfrcbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(\"[He didn’t like the U.S. movie “Snakes on a train, revenge of Viper-man!”, now playing in the U.K.]\")"
      ],
      "metadata": {
        "id": "_k-H8iyIr9Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(\"I placed an order (order# ZA10880) on 05-11-2020 for rear axle break discs for a BMW8Coupe - part no. B342r. DH-D have lost the order. Please re-deliver ASAP.\")"
      ],
      "metadata": {
        "id": "3-rkTAyAaMQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlQpSPOucVUB"
      },
      "outputs": [],
      "source": [
        "class ItemSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"For data grouped by feature, select subset of data at a provided key.    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_dict):\n",
        "        return data_dict[self.key]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**evaluation_summary() function prints out an evaluation summary with  performance metrics icluding accuracy, precision, recall and\tF1 Score as well as a 'classification report'**\n",
        "\n"
      ],
      "metadata": {
        "id": "cBTVbaxiBAcm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fPBLcI-cYW3"
      },
      "outputs": [],
      "source": [
        "def evaluation_summary(description, true_labels, predictions, target_classes):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  print(classification_report(true_labels, predictions,  digits=3, zero_division=0, target_names=target_classes))\n",
        "  #print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorization is a technique for converting text documents into numerical vectors. **Count Vectorizer** is one of the simplest ways to vectorize text. Fit the vectorizer model (with default settings) on the training data column ‘body’ to learn the word vocabulary and transform the text in column ‘body’ to a document term matrix in which the individual cells reflect term frequency within the document (each reddit post body), and the columns reflects each word in the corpus (entire train_data[‘body’]).In built tokenizer in CountVectorizer divides sentences into a collection of tokens in the lexicon. Punctuation and special characters are also removed."
      ],
      "metadata": {
        "id": "wNRIxSn1ANx0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLIMt_WpWGSQ"
      },
      "outputs": [],
      "source": [
        "# Create a one-hot encoding vectorizer. Pass in the tokenizer as the tokenizer to the vectorizer.\n",
        "onehot_vectorizer = CountVectorizer()\n",
        "tr_vector_onehot = onehot_vectorizer.fit_transform(train_data_df['body'].tolist())\n",
        "val__vector_onehot = onehot_vectorizer.transform(val_data_df['body'])\n",
        "test_vector_onehot = onehot_vectorizer.transform(test_data_df['body'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer**: It tells the model about the significance of a word in a dataset. It relies on two concepts-term frequency (TF) and inverse document frequency (IDF). The frequency with which a word appears in the document/corpus is indicated by TF.TF indicates how frequently a word is appeared in the document/corpus. The IDF is used to determine the significance of a word in a document. Words that occur less frequently are more informative. This vectorizer was used with the default settings and its built-in tokenizer."
      ],
      "metadata": {
        "id": "jeqGUd1Jg8Tk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEwY9QSr5a6T"
      },
      "outputs": [],
      "source": [
        "#create TF-IDF vectorization. Pass in the tokenizer as the tokenizer to the vectorizer.\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tr_vector_tfidf = tfidf_vectorizer.fit_transform(train_data_df['body'].tolist())\n",
        "val_vector_tfidf = tfidf_vectorizer.transform(val_data_df['body'])\n",
        "test_vector_tfidf = tfidf_vectorizer.transform(test_data_df['body'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting the labels for each of the datasets**"
      ],
      "metadata": {
        "id": "mhO0ukc9ASvF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS-ChAO5Wmsg"
      },
      "outputs": [],
      "source": [
        "train_labels = train_data_df['subreddit']\n",
        "val_labels = val_data_df['subreddit']\n",
        "test_labels = test_data_df['subreddit']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_T5BdRMPz8y"
      },
      "source": [
        "\n",
        "\n",
        "1.   **Dummy Classifier with strategy=\"most_frequent\"**\n",
        "\n",
        "\n",
        "*   This classifier is used as a baseline for other classifiers that means on the given dataset other classifiers are expected to perform better. It classifies the data using simple rules and predicts most frequent class label in the training dataset by ignoring the input feature values passed as the X argument to fit and predict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM6iIgeKRzxv"
      },
      "source": [
        "\n",
        "\n",
        "*   Training set - Trained dummy classifier on the training set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMuR70rWXMVW"
      },
      "outputs": [],
      "source": [
        "#Dummy Classifier with strategy=\"most_frequent\"\n",
        "dummy_frq = DummyClassifier(strategy=\"most_frequent\", random_state=1)\n",
        "dummy_frq.fit(tr_vector_onehot, train_labels)\n",
        "dummy_frq_predicted_tr = dummy_frq.predict(tr_vector_onehot)\n",
        "evaluation_summary(\"Dummy Classifier['most_frequent']: Training set\", train_labels, dummy_frq_predicted_tr,  uniquelabels_tr)\n",
        "ConfusionMatrixDisplay.from_predictions(train_labels,dummy_frq_predicted_tr,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "97KbCRzt-tjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-G1uSWnR3fr"
      },
      "source": [
        "*   Test set - predict the model on testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKAtW-SqJBKs"
      },
      "outputs": [],
      "source": [
        "#Dummy Classifier with strategy=\"most_frequent\" - test set\n",
        "dummy_frq_predicted_test = dummy_frq.predict(test_vector_onehot)\n",
        "evaluation_summary(\"Dummy Classifier['most_frequent: Test set']\", test_labels, dummy_frq_predicted_test,  uniquelabels_test)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels,dummy_frq_predicted_test,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation** : Trained dummy classifier on the training set and achieved a 12.2% accuracy with F1 score of 0.024(macro) and 0.026(weighted). Got 146 true positive values that correspond to reddit posts with label/subreddits of 'tea' and our model correctly identified them because we trained a dummy classifier with the \"most frequent\" parameter, which predicts the most common class label in the training dataset (ie., posts with subreddit 'tea'). Predict it on the test set after training, which resulted 10.5% of accuracy with F1 score of 0.021(macro) and 0.020(weighted). Model correctly identified 42 true positive values that correspond to reddit posts with label/subreddits of 'tea'."
      ],
      "metadata": {
        "id": "23bvVz_hxge4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKrw_mdyQADy"
      },
      "source": [
        "2.   **Dummy Classifier with strategy=\"stratified\"**\n",
        " : This is another type of dummy classifier which predicts on the basis of the label distribution of the training dataset. For example, if the reddit post with label ‘soda occurs about 8.5% of the time in the training set, then the dummy classifier will output ‘soda’ class with 8.5% probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mai2cIjTl8b"
      },
      "source": [
        "*   Training Set : Trained dummy classifier with stratified parameter on the training set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKf60jyPgLqr"
      },
      "outputs": [],
      "source": [
        "#Dummy Classifier with strategy=\"stratified\"\n",
        "dummy_str = DummyClassifier(strategy=\"stratified\", random_state=1)\n",
        "dummy_str.fit(tr_vector_onehot, train_labels)\n",
        "dummy_str_predicted_tr = dummy_str.predict(tr_vector_onehot)\n",
        "evaluation_summary(\"Dummy Classifier['stratified']: Training set\", train_labels, dummy_str_predicted_tr,  uniquelabels_tr)\n",
        "ConfusionMatrixDisplay.from_predictions(train_labels,dummy_str_predicted_tr,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JFQv7R7TpVT"
      },
      "source": [
        "*   Test Set : predict the model on test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtGmuJgFJai5"
      },
      "outputs": [],
      "source": [
        "#Dummy Classifier with strategy=\"stratified\" - test set\n",
        "dummy_str_predicted_test = dummy_str.predict(test_vector_onehot)\n",
        "evaluation_summary(\"Dummy Classifier['stratified']: Test set\", test_labels, dummy_str_predicted_test,  uniquelabels_test)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels,dummy_str_predicted_test,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL10-qLUQJJf"
      },
      "source": [
        "\n",
        "\n",
        "3.   **LogisticRegression with One-hot vectorization**\n",
        ": used to predict a dependent categorical target variable using sigmoid function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSZBboANUcTb"
      },
      "source": [
        "\n",
        "\n",
        "*   Training Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wiq8Jbxjiim"
      },
      "outputs": [],
      "source": [
        "#LogisticRegression with One-hot vectorization\n",
        "lr_clf = LogisticRegression(random_state=1)\n",
        "lr_model = lr_clf.fit(tr_vector_onehot, train_labels)\n",
        "lr_onehot_predicted_tr = lr_model.predict(tr_vector_onehot)\n",
        "evaluation_summary(\"LR onehot vectorization: Training set\", train_labels, lr_onehot_predicted_tr,  uniquelabels_tr)\n",
        "ConfusionMatrixDisplay.from_predictions(train_labels, lr_onehot_predicted_tr,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tVQW_phUuSh"
      },
      "source": [
        "\n",
        "\n",
        "*   Test Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4yJOqa6JriM"
      },
      "outputs": [],
      "source": [
        "#LogisticRegression with One-hot vectorization - test set\n",
        "lr_onehot_predicted_test = lr_model.predict(test_vector_onehot)\n",
        "evaluation_summary(\"LR onehot vectorization: Test set\", test_labels, lr_onehot_predicted_test,  uniquelabels_test)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels,lr_onehot_predicted_test,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRzDZh8AQOmW"
      },
      "source": [
        "\n",
        "\n",
        "4.   **LogisticRegression with TF-IDF vectorization (default settings)**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dniinGEVX-T"
      },
      "source": [
        "\n",
        "\n",
        "*   Training Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6DxuP2u6071"
      },
      "outputs": [],
      "source": [
        "#LogisticRegression with TF-IDF vectorization (default settings)\n",
        "lr_tfidf_clf = LogisticRegression(random_state=1)\n",
        "lr_tfidf_model = lr_tfidf_clf.fit(tr_vector_tfidf, train_labels)\n",
        "lr_tfidf_predicted_tr = lr_tfidf_model.predict(tr_vector_tfidf)\n",
        "evaluation_summary(\"LogisticRegression TF-IDF Vectorization: Training set\", train_labels, lr_tfidf_predicted_tr,  uniquelabels_tr)\n",
        "ConfusionMatrixDisplay.from_predictions(train_labels,lr_tfidf_predicted_tr,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfaE1LTNVl0v"
      },
      "source": [
        "\n",
        "\n",
        "*   Test Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkCZu4DyKApX"
      },
      "outputs": [],
      "source": [
        "#LogisticRegression with TF-IDF vectorization (default settings) - test set\n",
        "lr_tfidf_predicted_test = lr_tfidf_model.predict(test_vector_tfidf)\n",
        "evaluation_summary(\"LogisticRegression TF-IDF Vectorization: Test set\", test_labels, lr_tfidf_predicted_test,  uniquelabels_test)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels,lr_tfidf_predicted_test,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpBGL-o1QUn-"
      },
      "source": [
        "\n",
        "\n",
        "6.   **SVC Classifier with One-hot vectorization (SVM with RBF kernel, default settings))**\n",
        "\n",
        "Support Vectors Classifier maximize the distance between sample points and the hyperplane and find the best hyperplane to separate the different classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM9ImcavWVds"
      },
      "source": [
        "\n",
        "\n",
        "*   Training Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0ElcaLNT40X"
      },
      "outputs": [],
      "source": [
        "#SVC Classifier with One-hot vectorization (SVM with RBF kernel, default settings)) - train set\n",
        "svc_clf = svm.SVC(kernel='rbf')\n",
        "svc_model = svc_clf.fit(tr_vector_onehot, train_labels)\n",
        "svc_predicted_tr = svc_model.predict(tr_vector_onehot)\n",
        "evaluation_summary(\"SVC Classifier with One-hot vectorization: Training set \", train_labels, svc_predicted_tr,  uniquelabels_tr)\n",
        "ConfusionMatrixDisplay.from_predictions(train_labels,svc_predicted_tr,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x5m9PfcWg9Q"
      },
      "source": [
        "\n",
        "\n",
        "*   Test Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooHyDZ5Ewm3U"
      },
      "outputs": [],
      "source": [
        "#SVC Classifier with One-hot vectorization (SVM with RBF kernel, default settings)) - test set\n",
        "svc_predicted_test = svc_model.predict(test_vector_onehot)\n",
        "evaluation_summary(\"SVC Classifier with One-hot vectorization: Test set \", test_labels, svc_predicted_test,  uniquelabels_test)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels,svc_predicted_test,xticks_rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TziJs-n4XPUX"
      },
      "source": [
        "\n",
        "\n",
        "*   **Comparison** : Discuss the classifier performance in comparison to the others and preprocessing techniques\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label_trainset = [dummy_frq_predicted_tr,dummy_str_predicted_tr,lr_onehot_predicted_tr,lr_tfidf_predicted_tr,svc_predicted_tr]\n",
        "predicted_label_testset = [dummy_frq_predicted_test,dummy_str_predicted_test,lr_onehot_predicted_test,lr_tfidf_predicted_test,svc_predicted_test]\n",
        "classifier_set =['Dummy Classifier with strategy=\"most_frequent\"','Dummy Classifier with strategy=\"stratified\"','LogisticRegression with One-hot vectorization','LogisticRegression with TF-IDF vectorization','SVC Classifier with One-hot vectorization']\n",
        "index_set =['Precision : TrainingSet','Precision : TestSet','Recall : TrainingSet','Recall : TestSet','F1Score : TrainingSet','F1Score : TestSet','Accuracy : TrainingSet','Accuracy : TestSet']\n",
        "\n",
        "column_list=[]\n",
        "for i in range(5):\n",
        "  dict_train = classification_report(train_labels, predicted_label_trainset[i],  digits=3, zero_division=0, target_names=uniquelabels_tr, output_dict=True)\n",
        "  dict_test = classification_report(test_labels, predicted_label_testset[i],  digits=3, zero_division=0, target_names=uniquelabels_test, output_dict=True)\n",
        "  sublist=[]\n",
        "  sublist.append(round(dict_train['weighted avg']['precision'],3))\n",
        "  sublist.append(round(dict_test['weighted avg']['precision'],3))\n",
        "  sublist.append(round(dict_train['weighted avg']['recall'],3))\n",
        "  sublist.append(round(dict_test['weighted avg']['recall'],3))\n",
        "  sublist.append(round(dict_train['weighted avg']['f1-score'],3))\n",
        "  sublist.append(round(dict_test['weighted avg']['f1-score'],3))\n",
        "  sublist.append(round(dict_train['accuracy'],3))\n",
        "  sublist.append(round(dict_test['accuracy'],3))\n",
        "  column_list.append(sublist)\n",
        "\n",
        "col_arry = np.array(column_list)\n",
        "col_arry_T=col_arry.T\n",
        "best_indices=col_arry_T.argmax(axis=1)\n",
        "best_list=[]\n",
        "for i in best_indices:\n",
        "  best_list.append(classifier_set[i])\n",
        "\n",
        "df = pd.DataFrame(col_arry_T,columns=['Dummy:strategy=most_frequent','Dummy:strategy=stratified','LR:One-hot vectorization','LR:TF-IDF vectorization','SVC:One-hot vectorization'])\n",
        "df['Performance Metrics']= index_set\n",
        "df.set_index('Performance Metrics', inplace=True)\n",
        "df['Best'] = best_list\n",
        "df\n"
      ],
      "metadata": {
        "id": "HLStKLZlGQof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**According to the consolidated table above , the Logistic Regression classifier with TF-IDF vectorizer had the best accuracy, precision, recall and F1 scores (weighted-avg) on test dataset making it the most reliable machine learning classifier for this data set followed by LR and SVC classifiers with one hot vectorizer.**"
      ],
      "metadata": {
        "id": "mVqdrSH8m00c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **best performing classifier** (by weighted F1 in test set) Include a bar chart graph with the F1 score for each class - (subreddits on x-axis, F1 score on Y axis).\n",
        "\n"
      ],
      "metadata": {
        "id": "ifwefSdDrlCC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW2h8UL8cm5L"
      },
      "outputs": [],
      "source": [
        "#the best one\n",
        "ind = best_indices[5]\n",
        "evaluation_summary(classifier_set[ind], test_labels, predicted_label_testset[ind],  uniquelabels_test)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels, predicted_label_testset[ind],xticks_rotation='vertical')\n",
        "\n",
        "dict1 = classification_report(test_labels, predicted_label_testset[ind],  digits=3, zero_division=0, target_names=uniquelabels_test, output_dict=True)\n",
        "df = pd.DataFrame(list(dict1.items()), columns=['label','value'])\n",
        "new_df = df.T\n",
        "label_arr=[]\n",
        "score_arr=[]\n",
        "for i in range(len(new_df.columns)):\n",
        "  if new_df[i]['label'] in uniquelabels_test:\n",
        "    label_arr.append(new_df[i]['label'])\n",
        "    score_arr.append(np.round(new_df[i]['value'].get('f1-score'),3))\n",
        "\n",
        "label_df=pd.DataFrame({'subreddits': label_arr ,'F1_Score': score_arr}, index=label_arr)\n",
        "#label_df\n",
        "label_df.plot.bar()\n",
        "plt.title(classifier_set[ind])\n",
        "plt.xlabel(\"subreddits\")\n",
        "plt.ylabel(\"F1 score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBMJdw_j_8fx"
      },
      "source": [
        "### Q1c:   Choose your own classifier/tokenization/normalisations approach, and report on its performance with respect to the five previous ones on the test set. [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function removes emoticons and irrelavant symbols, pictographs etc from input text\n",
        "def remove_emoji(text_data):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text_data)\n",
        "#remove_emoji(\"Hi 🤔 How is your 🙈 and 😌. Have a nice weekend 💕👭👙\")"
      ],
      "metadata": {
        "id": "98mmYcrrqTsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function removes all html tags from input text\n",
        "def remove_html(text_data):\n",
        "  soup = BeautifulSoup(text_data, 'lxml')\n",
        "  return soup.get_text()\n",
        "#remove_html(\"<html><head></head><body onload=loadfunc()>my text<br/>\")"
      ],
      "metadata": {
        "id": "vY3IBYOUsSn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function that expands some commonly used english short forms\n",
        "def word_expansion(text_data):\n",
        "\n",
        "  text_data = re.sub(r\"won\\'t\", \"will not\", text_data)\n",
        "  text_data = re.sub(r\"can\\'t\", \"can not\", text_data)\n",
        "  text_data = re.sub(r\"won\\’t\", \"will not\", text_data)\n",
        "  text_data = re.sub(r\"can\\’t\", \"can not\", text_data)\n",
        "  text_data = re.sub(r\"n\\'t\", \" not\", text_data)\n",
        "  text_data = re.sub(r\"\\'re\", \" are\", text_data)\n",
        "  text_data = re.sub(r\"\\'s\", \" is\", text_data)\n",
        "  text_data = re.sub(r\"\\'d\", \" would\", text_data)\n",
        "  text_data = re.sub(r\"\\'ll\", \" will\", text_data)\n",
        "  text_data = re.sub(r\"\\'t\", \" not\", text_data)\n",
        "  text_data = re.sub(r\"\\'ve\", \" have\", text_data)\n",
        "  text_data = re.sub(r\"\\'m\", \" am\", text_data)\n",
        "  text_data = re.sub(r\"n\\’t\", \" not\", text_data)\n",
        "  text_data = re.sub(r\"\\’re\", \" are\", text_data)\n",
        "  text_data = re.sub(r\"\\’s\", \" is\", text_data)\n",
        "  text_data = re.sub(r\"\\’d\", \" would\", text_data)\n",
        "  text_data = re.sub(r\"\\’ll\", \" will\", text_data)\n",
        "  text_data = re.sub(r\"\\’t\", \" not\", text_data)\n",
        "  text_data = re.sub(r\"\\’ve\", \" have\", text_data)\n",
        "  text_data = re.sub(r\"\\’m\", \" am\", text_data)\n",
        "\n",
        "  return text_data"
      ],
      "metadata": {
        "id": "kPokkGUytFVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created a **custom tokenizer**(function name: custom_tokenizer ()) for converting the text (body of reddit post) into list of words assuming that the better we tokenize the body text, the better the final result will be."
      ],
      "metadata": {
        "id": "EdBQgMpZlKYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_tokenizer(text):\n",
        "    text = remove_html(text)    # Cleaning html elements if any\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)    # Cleaning urls if any\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "    text = remove_emoji(text)\n",
        "    text = word_expansion(text)\n",
        "    text = text.translate ({ord(char): \"\" for char in \"!@#$%^&*()[]{};':,./<>?\\|`~-=_+\"}) #remove all special characters\n",
        "    text = text.lower() #normalising - convert all words to lowercase by calling the lower() function on each word.\n",
        "    tokens = []\n",
        "    doc = nlp(text) #tokenize\n",
        "    for t in doc:\n",
        "        if not t.is_stop and not t.is_space:\n",
        "            tokens.append(t.lemma_) #lemmatization\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "SXuD5lbW1Bo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create TF-IDF vectorization. Pass in the tokenizer as the tokenizer to the vectorizer.\n",
        "tfidf_vectorizer_custom = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
        "tr_vector_tfidf_custom = tfidf_vectorizer.fit_transform(train_data_df['body'].tolist())\n",
        "test_vector_tfidf_custom = tfidf_vectorizer.transform(test_data_df['body'])"
      ],
      "metadata": {
        "id": "R3ZkLCUgIPmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGDClassifier(random_state=1)\n",
        "\n",
        "sgd_model = sgd.fit(tr_vector_tfidf_custom, train_labels)\n",
        "sgd_predicted_tr = sgd_model.predict(tr_vector_tfidf_custom)\n",
        "evaluation_summary(\"SGD with TF-IDF Vectorization with custom tokenizer: Traing set\", train_labels, sgd_predicted_tr,  uniquelabels_tr)\n",
        "\n",
        "sgd_predicted_test = sgd_model.predict(test_vector_tfidf_custom)\n",
        "evaluation_summary(\"SGD with TF-IDF Vectorization with custom tokenizer: Test set\", test_labels, sgd_predicted_test,  uniquelabels_test)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels, sgd_predicted_test,xticks_rotation='vertical')"
      ],
      "metadata": {
        "id": "EEuTITs_HVte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label_testset = [dummy_frq_predicted_test,dummy_str_predicted_test,lr_onehot_predicted_test,lr_tfidf_predicted_test,\n",
        "                           svc_predicted_test,sgd_predicted_test]\n",
        "classifier_set =['Dummy Classifier with strategy=\"most_frequent\"','Dummy Classifier with strategy=\"stratified\"','LogisticRegression with One-hot vectorization',\n",
        "                 'LogisticRegression with TF-IDF vectorization','SVC Classifier with One-hot vectorization','SGD Custom Tokenizer-TF-IDF Vectorization']\n",
        "index_set =['Precision','Recall','F1Score','Accuracy']\n",
        "\n",
        "column_list=[]\n",
        "for i in range(6):\n",
        "  dict_test = classification_report(test_labels, predicted_label_testset[i],  digits=3, zero_division=0, target_names=uniquelabels_test, output_dict=True)\n",
        "  sublist=[]\n",
        "  sublist.append(round(dict_test['weighted avg']['precision'],3))\n",
        "  sublist.append(round(dict_test['weighted avg']['recall'],3))\n",
        "  sublist.append(round(dict_test['weighted avg']['f1-score'],3))\n",
        "  sublist.append(round(dict_test['accuracy'],3))\n",
        "  column_list.append(sublist)\n",
        "\n",
        "col_arry = np.array(column_list)\n",
        "col_arry_T=col_arry.T\n",
        "best_indices=col_arry_T.argmax(axis=1)\n",
        "best_list=[]\n",
        "for i in best_indices:\n",
        "  best_list.append(classifier_set[i])\n",
        "\n",
        "df = pd.DataFrame(col_arry_T,columns=['Dummy:most_frequent','Dummy:stratified','LR:One-hot','LR:TF-IDF','SVC:Onehot','SGD:TFIDF:Custom'])\n",
        "df['Performance Metrics']= index_set\n",
        "df.set_index('Performance Metrics', inplace=True)\n",
        "df['Best'] = best_list\n",
        "df"
      ],
      "metadata": {
        "id": "haoaN2y14q0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2)= plt.subplots(1, 2,figsize=(20,5))\n",
        "plot_df = df[df.index == 'F1Score']\n",
        "plot_df.plot.bar(ax=ax1)\n",
        "ax1.title.set_text(\"F1 Score Comparison\")\n",
        "ax1.set(xlabel='classifier/tokenization/normalisations approach on test data', ylabel='F1_Score')\n",
        "\n",
        "plot_df = df[df.index == 'Accuracy']\n",
        "plot_df.plot.bar(ax=ax2)\n",
        "ax2.title.set_text(\"Accuracy Comparison\")\n",
        "ax2.set(xlabel='classifier/tokenization/normalisations approach on test data', ylabel='Accuracy')"
      ],
      "metadata": {
        "id": "q8UNbVpJYCqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZcRes8WAOo6"
      },
      "source": [
        "## Q2: Tuning and Error Analysis [10 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuAxwU0IABir"
      },
      "source": [
        "* ### **Q2a: Parameter tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression with TF-IDF vectorization is identified as the most reliable classifier from Q1.b. Further improving model performance CV-fold validation on training set using grid search strategy used for parameter tuning. Below parameters are used for tuning"
      ],
      "metadata": {
        "id": "l9-noDmnvpuj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f8LOI6N7iQS"
      },
      "outputs": [],
      "source": [
        "#LR- TFIDF Vectorizer before paramter tuning\n",
        "prediction_pipeline = Pipeline([\n",
        "              ('selector', ItemSelector(key='body')),\n",
        "              ('tf-idf', TfidfVectorizer()),\n",
        "              ('logreg', LogisticRegression(random_state=1))\n",
        "              ])\n",
        "prediction_pipeline.fit(train_data_df, train_labels)\n",
        "evaluation_summary(\"LR-TFIDF : Before parameter tuning: training set\", train_labels, prediction_pipeline.predict(train_data_df), uniquelabels_tr)\n",
        "evaluation_summary(\"LR-TFIDF : Before parameter tuning: test set\", test_labels, prediction_pipeline.predict(test_data_df), uniquelabels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A0MJCaeFEIo"
      },
      "outputs": [],
      "source": [
        "print(\"LR cssifier available paramters:\" ,lr_tfidf_clf.get_params().keys())\n",
        "print(\"Pipeline available paramters:\", prediction_pipeline.get_params().keys())\n",
        "print(\"TF IDF vectorizer available paramters:\" ,tfidf_vectorizer.get_params().keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sdfLXLKAY5Z"
      },
      "outputs": [],
      "source": [
        "#Tuning paramters to improve model performance\n",
        "parameters = {\n",
        "    'tf-idf__sublinear_tf':[True,False],\n",
        "    \"logreg__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    \"tf-idf__max_features\": [None,1000,1100,1200,1300,1400,1500],\n",
        "    #\"logreg__max_iter\" : [1000,2000,3000,4000,5000]\n",
        "    #'tf-idf__max_df':np.linspace(0.1, 1, 10),\n",
        "    #'tf-idf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "    #'logreg__max_iter':[100,200,300,400,500]\n",
        "    #'logreg__solver' : ['newton-cg', 'liblinear',  'sag','saga'],\n",
        "    #\"tf-idf__norm\" : ['l1', 'l2'],\n",
        "    #\"logreg__penalty\":['none','elasticnet','l1','l2'],\n",
        "    #\"logreg__class_weight\":['balanced'],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(prediction_pipeline, param_grid=parameters, n_jobs=1, verbose=1, scoring='f1_weighted', cv=2)\n",
        "\n",
        "print(\"Performing grid search...\")\n",
        "print(\"pipeline:\", [name for name, _ in prediction_pipeline.steps])\n",
        "print(\"parameters:\")\n",
        "pprint(parameters)\n",
        "t0 = time()\n",
        "grid_search.fit(train_data_df, train_labels)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print()\n",
        "\n",
        "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = grid_search.best_estimator_.get_params()\n",
        "for param_name in sorted(parameters.keys()):\n",
        "  print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR with TF-IDF vectorization. Passing tuned paramters.  Pass text_pipeline_spacy tokenizer to the vectorizer.\n",
        "prediction_pipeline_tuned = Pipeline([\n",
        "              ('selector', ItemSelector(key='body')),\n",
        "              ('tf-idf', TfidfVectorizer(sublinear_tf=True,max_features=None, tokenizer=text_pipeline_spacy))\n",
        "              ])\n",
        "\n",
        "tf_idf_train_tuned = prediction_pipeline_tuned.fit_transform(train_data_df)\n",
        "tf_idf_validation_tuned = prediction_pipeline_tuned.transform(val_data_df)\n",
        "tf_idf_test_tuned = prediction_pipeline_tuned.transform(test_data_df)\n",
        "\n",
        "lr = LogisticRegression(random_state=1, C=100)\n",
        "tr_tuned_model = lr.fit(tf_idf_train_tuned,train_labels)\n",
        "\n",
        "#train set\n",
        "lr_tfidf_tuned_val = lr.predict(tf_idf_validation_tuned)\n",
        "evaluation_summary(\"LR - TF IDF with paramter tuning on Validation set\", val_labels, lr_tfidf_tuned_val , uniquelabels_val)\n",
        "\n",
        "lr_tfidf_tuned_test = lr.predict(tf_idf_test_tuned)\n",
        "evaluation_summary(\"LR - TF IDF with paramter tuning on Test set\", test_labels, lr_tfidf_tuned_test , uniquelabels_test)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels,lr_tfidf_tuned_test,xticks_rotation='vertical')"
      ],
      "metadata": {
        "id": "J20eUJr760Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label_testset = [lr_tfidf_predicted_test,lr_tfidf_tuned_test]\n",
        "classifier_set =['LR-TF-IDF vectorization','LR-TF-IDF Vectorization with Parameter Tuning']\n",
        "index_set =['Precision','Recall','F1Score','Accuracy']\n",
        "\n",
        "column_list=[]\n",
        "for i in range(2):\n",
        "  dict_test = classification_report(test_labels, predicted_label_testset[i],  digits=3, zero_division=0, target_names=uniquelabels_test, output_dict=True)\n",
        "  sublist=[]\n",
        "  sublist.append(round(dict_test['weighted avg']['precision'],3))\n",
        "  sublist.append(round(dict_test['weighted avg']['recall'],3))\n",
        "  sublist.append(round(dict_test['weighted avg']['f1-score'],3))\n",
        "  sublist.append(round(dict_test['accuracy'],3))\n",
        "  column_list.append(sublist)\n",
        "\n",
        "col_arry = np.array(column_list)\n",
        "col_arry_T=col_arry.T\n",
        "best_indices=col_arry_T.argmax(axis=1)\n",
        "best_list=[]\n",
        "for i in best_indices:\n",
        "  best_list.append(classifier_set[i])\n",
        "\n",
        "df = pd.DataFrame(col_arry_T,columns=['LR-TF-IDF vectorization (Q1.b)','LR-TF-IDF Vectorization with Parameter Tuning (Q2.a)'])\n",
        "df['Performance Metrics']= index_set\n",
        "df.set_index('Performance Metrics', inplace=True)\n",
        "df['Best'] = best_list\n",
        "df"
      ],
      "metadata": {
        "id": "R4ehNOYbqePN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1= plt.subplots(1, 1,figsize=(10,5))\n",
        "df.plot.line(ax=ax1)\n",
        "ax1.set(ylabel='Value')"
      ],
      "metadata": {
        "id": "l_T5NNYhwAjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIsRTiW-ABs8"
      },
      "source": [
        "* ### Q2b: Error analysis - Manually examine the predictions of your optimised classifier on the test set. Analyse the results for patterns and trends. Hypothesise why common classification errors are made. Report on your error analysis process and summarise your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWs7YqOOAbLp"
      },
      "source": [
        "## Q3: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOpWB9pMAcri"
      },
      "source": [
        "### Q3a:\n",
        "Below features are selected to add to the tuned model from Q2.\n",
        "\n",
        "\n",
        "1.   Added other properties of reddit posts.\n",
        "‘Title’ has been added as an additional feature. In a normal context, title of a reddit post shows a very brief description of the subreddit. It will be shown in the tab's text, as well as in Reddit and Google search results. As a result, if we add title as a new feature, there may be a significant increase in classifier performance.\n",
        "2.   Word embedding using Gensim word2vec\n",
        "word2vec is used for word embedding. Reddit post ‘title’ has been passed to gensim function created. Since it is capable of capturing word similarity using vector arithmetic, it may improve model performance. Also size of generated vector is small and flexible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3b:"
      ],
      "metadata": {
        "id": "Q6CEo84D1sqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GensimSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"For data grouped by feature, select subset of data at a provided key.    \"\"\"\n",
        "\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_dict):\n",
        "        return data_dict[self.key]"
      ],
      "metadata": {
        "id": "I4w9HFdKkc1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GensimFun(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, posts):\n",
        "        model = gensim.models.Word2Vec(window=10, min_count=1, workers=4, size=25)\n",
        "        token_list=[]\n",
        "        for i in range(len(posts)):\n",
        "          tokens = gensim.utils.simple_preprocess(posts[i])\n",
        "          token_list.append(tokens)\n",
        "\n",
        "        model.build_vocab(token_list, progress_per=1000)\n",
        "\n",
        "        model.train(posts, total_examples=model.corpus_count, epochs=model.iter)\n",
        "        model.save('./my_test_vocab.model')\n",
        "        final_vec_arr=[]\n",
        "        for i in range(len(posts)):\n",
        "            tokens = gensim.utils.simple_preprocess(posts[i])\n",
        "            model.train(tokens, total_examples=model.corpus_count, epochs=model.iter)\n",
        "            if len(tokens)>0:\n",
        "              tmp = np.sum(model.wv[tokens],axis=0)\n",
        "            else:\n",
        "              tmp = np.empty(25, dtype=float)\n",
        "            final_vec_arr.append(tmp)\n",
        "        final_vec_arr = np.array(list(final_vec_arr))\n",
        "        return final_vec_arr"
      ],
      "metadata": {
        "id": "BgT9LRhOn7a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Use FeatureUnion to combine the features from text and summary\n",
        "prediction_pipeline_feature = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "          transformer_list=[\n",
        "            ('body', Pipeline([\n",
        "              ('selector', ItemSelector(key='body')),\n",
        "              ('tf-idf', TfidfVectorizer(sublinear_tf=True, max_features=None,tokenizer=text_pipeline_spacy)),\n",
        "              ])),\n",
        "            ('title', Pipeline([\n",
        "              ('selector', GensimSelector(key='title')),\n",
        "              ('w2v', GensimFun())\n",
        "              ])),\n",
        "        ])\n",
        "        )\n",
        "    ])\n",
        "\n",
        "tf_idf_train_features2 = prediction_pipeline_feature.fit_transform(train_data_df)\n",
        "tf_idf_validation_features2 = prediction_pipeline_feature.transform(val_data_df)\n",
        "tf_idf_test_features2 = prediction_pipeline_feature.transform(test_data_df)\n",
        "\n",
        "lr = LogisticRegression(random_state=1, C=100)\n",
        "combined_model = lr.fit(tf_idf_train_features2,train_labels)\n",
        "\n",
        "#train set\n",
        "tf_idf_feature_model = lr.predict(tf_idf_train_features2)\n",
        "evaluation_summary(\"LR TFIDF(fine tuned) with feature addition- trainset\", train_labels,tf_idf_feature_model , uniquelabels_tr)\n",
        "ConfusionMatrixDisplay.from_predictions(train_labels,tf_idf_feature_model,xticks_rotation='vertical')\n",
        "\n",
        "#validation set\n",
        "tf_idf_val_feature_model = lr.predict(tf_idf_validation_features2)\n",
        "evaluation_summary(\"LR TFIDF(fine tuned) with feature addition- validation set\", val_labels,tf_idf_val_feature_model , uniquelabels_val)\n",
        "ConfusionMatrixDisplay.from_predictions(val_labels,tf_idf_val_feature_model,xticks_rotation='vertical')\n",
        "\n",
        "#test set\n",
        "tf_idf_test_features_model = lr.predict(tf_idf_test_features2)\n",
        "evaluation_summary(\"LR TFIDF(fine tuned) with feature addition- testset\", test_labels,tf_idf_test_features_model , uniquelabels_test)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels,tf_idf_test_features_model,xticks_rotation='vertical')"
      ],
      "metadata": {
        "id": "R0to1MdNKKW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSw1OczAAgb3"
      },
      "source": [
        "### Q3c:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label_testset = [lr_tfidf_predicted_test,lr_tfidf_tuned_test,tf_idf_test_features_model]\n",
        "classifier_set =['LR-TF-IDF vectorization','LR-TF-IDF Vectorization with Parameter Tuning','LR-TF-IDF-Param Tuning-Feature Engineering']\n",
        "index_set =['Precision','Recall','F1Score','Accuracy']\n",
        "\n",
        "column_list=[]\n",
        "for i in range(3):\n",
        "  dict_test = classification_report(test_labels, predicted_label_testset[i],  digits=3, zero_division=0, target_names=uniquelabels_test, output_dict=True)\n",
        "  sublist=[]\n",
        "  sublist.append(round(dict_test['weighted avg']['precision'],3))\n",
        "  sublist.append(round(dict_test['weighted avg']['recall'],3))\n",
        "  sublist.append(round(dict_test['weighted avg']['f1-score'],3))\n",
        "  sublist.append(round(dict_test['accuracy'],3))\n",
        "  column_list.append(sublist)\n",
        "\n",
        "col_arry = np.array(column_list)\n",
        "col_arry_T=col_arry.T\n",
        "best_indices=col_arry_T.argmax(axis=1)\n",
        "best_list=[]\n",
        "for i in best_indices:\n",
        "  best_list.append(classifier_set[i])\n",
        "\n",
        "df = pd.DataFrame(col_arry_T,columns=['LR-TF-IDF (Q1.b)','LR-TF-IDF with Param Tuning (Q2.a)','LR-TF-IDF-Param Tuning-Feature Engineering'])\n",
        "df['Performance Metrics']= index_set\n",
        "df.set_index('Performance Metrics', inplace=True)\n",
        "df['Best'] = best_list\n",
        "df"
      ],
      "metadata": {
        "id": "hdslU7ZaWYbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1= plt.subplots(1, 1,figsize=(10,5))\n",
        "df.plot.line(ax=ax1)\n",
        "ax1.set(ylabel='Value')"
      ],
      "metadata": {
        "id": "rd_bHU1gWa3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9Q1WlLmaGeZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}